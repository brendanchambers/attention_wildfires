{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'data_processing_feb2020/pmids_2018_100k_baseline.json'  # name to assign exported results\n",
    "model_export_prefix = '2018_100k_baseline'\n",
    "\n",
    "K_sample = 100000   # rule of thumb - at least 5K samples per cluster for abstracts analysis\n",
    "                   #                 - at least 25K samples per cluster for titles analysis\n",
    "\n",
    "N_samplesets = 3\n",
    "year = 2018\n",
    "path2dir = '/home/brendan/FastData/pubmed2019/pubmed_data_processing/year_pmids/'  # knowledge-garden\n",
    "        #path2dir = '/project2/jevans/brendan/pubmed_data_processing/year_pmids/'  # RCC Midway2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/brendan/Projects/AttentionWildfires/attention_wildfires/mysql_config.json'\n",
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "                        # todo should move this db_name into config file\n",
    "with open(config_path, 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "    \n",
    "client_config = {'database': db_name,\n",
    "                'user': config_data['user'],\n",
    "                 'password': config_data['lock']}\n",
    "\n",
    "## init db connection\n",
    "db = pymysql.connect(**client_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N pubs: 1205220\n"
     ]
    }
   ],
   "source": [
    "filename = 'pubmed_state_{}'.format(year)\n",
    "path2pmids = path2dir + filename\n",
    "with open(path2pmids,'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "year_pub_pmids = data['publications']\n",
    "N_pubs = len(year_pub_pmids)\n",
    "print(\"N pubs: {}\".format(N_pubs))\n",
    "del data # clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "for i in range(N_samplesets):\n",
    "    samples[i] = {}\n",
    "    samples[i]['pmids'] = np.random.choice(year_pub_pmids, K_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "sample 1\n",
      "sample 2\n"
     ]
    }
   ],
   "source": [
    "pmids = {}  # for export\n",
    "for i_sample in range(N_samplesets):\n",
    "    print(\"sample {}\".format(i_sample))\n",
    "    \n",
    "    pmids[i_sample] = samples[i_sample]['pmids'].tolist()   # for export\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj = {'pmids': pmids}\n",
    "\n",
    "with open(target_file,'w') as f:\n",
    "    json.dump(save_obj, f, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2baselinePMIDs = target_file  # use the file we just saved\n",
    "embed_titles_text = True\n",
    "embed_abstracts_text = True\n",
    "\n",
    "N_samples = len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 40.69608807563782 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.6567766666412354 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 5000 min count\n",
      "elapsed: 204.728924036026\n",
      "calling pmids2vec...\n",
      "SQL join executed in 49.44707918167114 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.7187507152557373 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 5000 min count\n",
      "elapsed: 243.15041422843933\n",
      "calling pmids2vec...\n",
      "SQL join executed in 43.64170861244202 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.7757980823516846 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 5000 min count\n",
      "elapsed: 135.54032826423645\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/abstracts_{}_baseline_{}.model'.format(\n",
    "                                sample_id, model_export_prefix)\n",
    "        model_names.append(model_export_path)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec(pmids[sample_id], model_export_path)\n",
    "            \n",
    "    print('--------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2corpus...\n",
      "SQL join executed in 41.72226142883301 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.4413745403289795 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_baseline_2018_500k_baseline_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 35.266695976257324 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.3869459629058838 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_baseline_2018_500k_baseline_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 46.53581190109253 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.5192344188690186 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_baseline_2018_500k_baseline_corpus.json\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        corpus_export_path = 'data_processing_feb2020/abstracts_{}_baseline_{}_corpus.json'.format(\n",
    "                                sample_id, model_export_prefix)\n",
    "        model_names.append(corpus_export_path)\n",
    "\n",
    "        print('calling pmids2corpus...')\n",
    "        pmids2corpus(pmids[sample_id], corpus_export_path)\n",
    "            \n",
    "    print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 42.63529896736145 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.3005862236022949 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_baseline_2018_500k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 500 min count\n",
      "elapsed: 20.610513925552368\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 48.69512963294983 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.31005001068115234 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_baseline_2018_500k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 500 min count\n",
      "elapsed: 16.33456301689148\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 49.06857490539551 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 0.29843807220458984 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_baseline_2018_500k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 500 min count\n",
      "elapsed: 14.366332530975342\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load pmids\n",
    "\n",
    "if embed_titles_text:\n",
    "    \n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "                                 #  need a large set of pmids since this is titles only\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/titles_{}_baseline_{}'.format(\n",
    "                sample_id, model_export_prefix)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec_titlesOnly(pmids[sample_id], model_export_path)\n",
    "            \n",
    "        print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
