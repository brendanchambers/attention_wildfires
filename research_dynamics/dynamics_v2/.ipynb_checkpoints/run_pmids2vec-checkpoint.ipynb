{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2clusteredPMIDs = 'data_processing_feb2020/pmids_2018_250k.json'\n",
    "model_export_prefix = '2018_50k'\n",
    "embed_titles_text = True\n",
    "embed_abstracts_text = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2clusteredPMIDs, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "N_samples = len(data['pmids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed abstract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 41.85774827003479 s\n",
      "SQL results fetched and cast in 0.015706539154052734 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 7.961929798126221\n",
      "calling pmids2vec...\n",
      "SQL join executed in 40.65176296234131 s\n",
      "SQL results fetched and cast in 0.006037235260009766 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 3.0556695461273193\n",
      "calling pmids2vec...\n",
      "SQL join executed in 44.107752561569214 s\n",
      "SQL results fetched and cast in 0.013501405715942383 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 8.80967116355896\n",
      "calling pmids2vec...\n",
      "SQL join executed in 39.87824749946594 s\n",
      "SQL results fetched and cast in 0.016404390335083008 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 7.9926722049713135\n",
      "calling pmids2vec...\n",
      "SQL join executed in 44.23684525489807 s\n",
      "SQL results fetched and cast in 0.004036903381347656 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 3.0444436073303223\n",
      "calling pmids2vec...\n",
      "SQL join executed in 41.41605353355408 s\n",
      "SQL results fetched and cast in 0.01709723472595215 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 9.589443445205688\n",
      "calling pmids2vec...\n",
      "SQL join executed in 42.5740122795105 s\n",
      "SQL results fetched and cast in 0.010277032852172852 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 7.715123176574707\n",
      "calling pmids2vec...\n",
      "SQL join executed in 42.419044971466064 s\n",
      "SQL results fetched and cast in 0.007941484451293945 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 3.456465482711792\n",
      "calling pmids2vec...\n",
      "SQL join executed in 42.60639142990112 s\n",
      "SQL results fetched and cast in 0.010109186172485352 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 8.216861724853516\n"
     ]
    }
   ],
   "source": [
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}.model'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(model_export_path)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec(pmids_list, model_export_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2corpus...\n",
      "SQL join executed in 40.627949714660645 s\n",
      "SQL results fetched and cast in 0.010574579238891602 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 42.31782245635986 s\n",
      "SQL results fetched and cast in 0.00613093376159668 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 42.913472175598145 s\n",
      "SQL results fetched and cast in 0.015854597091674805 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster2_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 42.918598890304565 s\n",
      "SQL results fetched and cast in 0.010352373123168945 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 43.48508048057556 s\n",
      "SQL results fetched and cast in 0.0036995410919189453 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 42.803284645080566 s\n",
      "SQL results fetched and cast in 0.01844644546508789 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster2_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 39.594810485839844 s\n",
      "SQL results fetched and cast in 0.016384601593017578 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 41.78572130203247 s\n",
      "SQL results fetched and cast in 0.0043332576751708984 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 42.47793459892273 s\n",
      "SQL results fetched and cast in 0.017034292221069336 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster2_2018_50k_corpus.json\n"
     ]
    }
   ],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            corpus_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}_corpus.json'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(corpus_export_path)\n",
    "\n",
    "            print('calling pmids2corpus...')\n",
    "            pmids2corpus(pmids_list, corpus_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed titles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 31.25151252746582 s\n",
      "SQL results fetched and cast in 0.04737281799316406 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster0_2018_50k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 3.403808355331421\n",
      "calling pmids2vec...\n"
     ]
    }
   ],
   "source": [
    "# titles only (saves the corpus while training the titles-only models)\n",
    "\n",
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_titles_text:\n",
    "    \n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "                                 #  todo need much larger set of pmids since this is titles only\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/titles_{}_cluster{}_{}'.format(\n",
    "                    sample_id, cluster_id_str, model_export_prefix)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec_titlesOnly(pmids_list, model_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
