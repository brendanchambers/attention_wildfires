{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2clusteredPMIDs = 'data_processing_feb2020/pmids_2018_25k.json'\n",
    "model_export_prefix = '2018_25k'\n",
    "embed_titles_text = False\n",
    "embed_abstracts_text = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2clusteredPMIDs, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "N_samples = len(data['pmids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed abstract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 47.785823345184326 s\n",
      "SQL results fetched and cast in 0.0067005157470703125 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 3.505244016647339\n",
      "calling pmids2vec...\n",
      "SQL join executed in 36.057719469070435 s\n",
      "SQL results fetched and cast in 0.012958049774169922 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 7.862300872802734\n",
      "calling pmids2vec...\n",
      "SQL join executed in 27.891879320144653 s\n",
      "SQL results fetched and cast in 0.0201873779296875 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 11.623611211776733\n",
      "calling pmids2vec...\n",
      "SQL join executed in 55.31189560890198 s\n",
      "SQL results fetched and cast in 0.003916501998901367 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 4.1429712772369385\n",
      "calling pmids2vec...\n",
      "SQL join executed in 44.63501596450806 s\n",
      "SQL results fetched and cast in 0.01460409164428711 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 10.338223218917847\n",
      "calling pmids2vec...\n",
      "SQL join executed in 28.4676992893219 s\n",
      "SQL results fetched and cast in 0.014188289642333984 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 10.820799350738525\n",
      "calling pmids2vec...\n",
      "SQL join executed in 60.19490194320679 s\n",
      "SQL results fetched and cast in 0.006383419036865234 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 5.066463947296143\n",
      "calling pmids2vec...\n",
      "SQL join executed in 27.41524386405945 s\n",
      "SQL results fetched and cast in 0.017713069915771484 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 8.380025625228882\n",
      "calling pmids2vec...\n",
      "SQL join executed in 27.58771252632141 s\n",
      "SQL results fetched and cast in 0.018258333206176758 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 25 window size, 10 min count\n",
      "elapsed: 10.478448152542114\n"
     ]
    }
   ],
   "source": [
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}.model'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(model_export_path)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec(pmids_list, model_export_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2corpus...\n",
      "SQL join executed in 27.742989778518677 s\n",
      "SQL results fetched and cast in 0.004819393157958984 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 26.35375428199768 s\n",
      "SQL results fetched and cast in 0.015481710433959961 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 25.719104766845703 s\n",
      "SQL results fetched and cast in 0.027425050735473633 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_cluster2_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 28.997007131576538 s\n",
      "SQL results fetched and cast in 0.006962299346923828 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 27.661071062088013 s\n",
      "SQL results fetched and cast in 0.0158078670501709 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 28.823567152023315 s\n",
      "SQL results fetched and cast in 0.016561269760131836 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_cluster2_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 26.5173556804657 s\n",
      "SQL results fetched and cast in 0.0070989131927490234 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster0_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 25.869349718093872 s\n",
      "SQL results fetched and cast in 0.013917207717895508 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster1_2018_50k_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 26.244255781173706 s\n",
      "SQL results fetched and cast in 0.017578840255737305 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_cluster2_2018_50k_corpus.json\n"
     ]
    }
   ],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            corpus_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}_corpus.json'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(corpus_export_path)\n",
    "\n",
    "            print('calling pmids2corpus...')\n",
    "            pmids2corpus(pmids_list, corpus_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed titles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# titles only (saves the corpus while training the titles-only models)\n",
    "\n",
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_titles_text:\n",
    "    \n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "                                 #  todo need much larger set of pmids since this is titles only\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/titles_{}_cluster{}_{}'.format(\n",
    "                    sample_id, cluster_id_str, model_export_prefix)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec_titlesOnly(pmids_list, model_export_path)\n",
    "            \n",
    "        print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
