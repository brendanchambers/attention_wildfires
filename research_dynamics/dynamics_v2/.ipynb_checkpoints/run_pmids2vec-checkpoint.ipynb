{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import igraph\n",
    "import cairocffi as cairo\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec\n",
    "from pmids2corpus import pmids2corpus\n",
    "\n",
    "\n",
    "\n",
    "#import cairocffi\n",
    "#cairocffi.install_as_pycairo()\n",
    "#import cairo\n",
    "#assert cairo is cairocffi\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 28.66690230369568 s\n",
      "SQL results fetched and cast in 0.020930051803588867 s\n",
      "training word2vec model...\n",
      "params: 25 dimensions, 15 window size, 25 min count\n",
      "elapsed: 10.331855773925781\n",
      "calling pmids2vec...\n"
     ]
    }
   ],
   "source": [
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "sample_id = 1\n",
    "model_names = []\n",
    "\n",
    "clustered_pmids_path = 'data_processing/clusters_for_dec12_meeting.json'\n",
    "with open(clustered_pmids_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "#print(data['pmids'])   # i_sample, i_cluster\n",
    "\n",
    "sample_pmids = []\n",
    "\n",
    "\n",
    "clustered_pmids = data['pmids'][str(sample_id)]\n",
    "for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "    \n",
    "    model_export_path = 'data_processing/cluster' + cluster_id_str + '.model'\n",
    "    model_names.append(model_export_path)\n",
    "    \n",
    "    print('calling pmids2vec...')\n",
    "    pmids2vec(pmids_list, model_export_path)\n",
    "    \n",
    "\n",
    "#print(data['pmids'])\n",
    "\n",
    "# perhaps try the mplcairo backend?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "sample_id = 1\n",
    "model_names = []\n",
    "\n",
    "clustered_pmids_path = 'data_processing/clusters_for_dec12_meeting.json'\n",
    "with open(clustered_pmids_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sample_pmids = []\n",
    "\n",
    "\n",
    "clustered_pmids = data['pmids'][str(sample_id)]\n",
    "for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "    \n",
    "    corpus_export_path = 'data_processing/cluster' + cluster_id_str + '_corpus.json'\n",
    "    model_names.append(corpus_export_path)\n",
    "    \n",
    "    print('calling pmids2corpus...')\n",
    "    pmids2corpus(pmids_list, corpus_export_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
