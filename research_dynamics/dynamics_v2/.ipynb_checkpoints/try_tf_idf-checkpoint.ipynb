{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2dir = 'data_processing_feb2020/titles_2018_250k/'\n",
    "outfile='tfidf_results.json'\n",
    "N_samples = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### list the paths to the respective corpus in a standardized order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], []]\n"
     ]
    }
   ],
   "source": [
    "corpus_paths = []\n",
    "\n",
    "files_list = [f for f in os.listdir(path2dir) if 'corpus.json' in f]\n",
    "\n",
    "for i_sample in range(N_samples):\n",
    "    \n",
    "    # NOTE this switch for titles vs abstracts (todo clean this up)\n",
    "    corpus_sublist = [f for f in files_list if 'titles_{}_'.format(i_sample) in f]\n",
    "    #corpus_sublist = [f for f in files_list if 'abstracts_{}_'.format(i_sample) in f]\n",
    "    \n",
    "    N_communities = len(corpus_sublist)\n",
    "    \n",
    "    corpus_paths.append([])\n",
    "    for i_community in range(N_communities):\n",
    "        \n",
    "        for j_path in corpus_sublist:\n",
    "            if 'cluster{}'.format(i_community) in j_path:\n",
    "                this_path = j_path\n",
    "        corpus_paths[i_sample].append(this_path)\n",
    "  \n",
    "'''\n",
    "KEY:\n",
    "sample 0\n",
    "    community 0\n",
    "    community 1\n",
    "    etc\n",
    "sample 1\n",
    "    community 0\n",
    "    community 1\n",
    "    etc\n",
    "etc\n",
    "'''\n",
    "\n",
    "print(corpus_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf on cluster text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge articles into one large document per community\n",
    "###   run tfidf to distinguish these communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate list of top tfidf words for each sample, over each cluster\n",
    "\n",
    "d = []\n",
    "for i_sample in range(N_samples):\n",
    "    \n",
    "    N_communities = len(corpus_paths[i_sample])\n",
    "    sample_texts = []\n",
    "    for i_community in range(N_communities):\n",
    "\n",
    "        cluster_text = []\n",
    "        full_path = path2dir + corpus_paths[i_sample][i_community]\n",
    "        with open(full_path,'r') as f:\n",
    "            documents = json.load(f)\n",
    "\n",
    "        N_words = 0\n",
    "        for doc_text in documents:  # list of e.g. titles\n",
    "            for word in doc_text:   #   list of words\n",
    "                \n",
    "                cluster_text.append(word)\n",
    "\n",
    "        print(\"{} words in sample {} cluster {}\".format(\n",
    "                    len(cluster_text),\n",
    "                    i_sample,\n",
    "                    i_community))\n",
    "        print()\n",
    "        \n",
    "        # here - optionally, stopwords\n",
    "        # here - optionally, filter based on wordfrequency\n",
    "        sample_texts.append(cluster_text)\n",
    "        \n",
    "    sample_dictionary = Dictionary(sample_texts)\n",
    "    sample_corpus = [sample_dictionary.doc2bow(t) for t in sample_texts]\n",
    "    sample_tfidf_model = TfidfModel(sample_corpus)   # computes idf\n",
    "    sample_tfidf = sample_tfidf_model[sample_corpus]  # applies tfidf\n",
    "    \n",
    "    d.append([])  # list of dicts for this sample\n",
    "    for i_community, community_doc in enumerate(sample_tfidf):\n",
    "        \n",
    "        scores = [t[1] for t in community_doc]\n",
    "        P_thresh = 99.9\n",
    "        thresh = np.percentile(scores, P_thresh)\n",
    "        print(\"score threshold: {}\".format(thresh))\n",
    "        subset = [t for t in community_doc if t[1] >= thresh]\n",
    "        print(len(subset))\n",
    "        d_tfidf = {}\n",
    "        for (w_id, score) in subset:\n",
    "            w = sample_dictionary[w_id]\n",
    "            d_tfidf[w] = score\n",
    "        d[i_sample].append( d_tfidf )\n",
    "        \n",
    "        print(sorted(d[i_sample][i_community],\n",
    "                     key=d[i_sample][i_community].get,\n",
    "                     reverse=True)[:100])\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = path2dir + outfile\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(d, f,\n",
    "             sort_keys=True,\n",
    "             indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
