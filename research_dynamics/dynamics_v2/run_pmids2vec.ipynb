{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2clusteredPMIDs = 'data_processing_feb2020/abstracts_2018_250k.json'\n",
    "model_export_prefix = '2018_250k'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2clusteredPMIDs, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "N_samples = len(data['pmids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 26.414577960968018 s\n",
      "SQL results fetched and cast in 0.027701616287231445 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 16.80997061729431\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.730005741119385 s\n",
      "SQL results fetched and cast in 0.05427289009094238 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 41.23099207878113\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.86283016204834 s\n",
      "SQL results fetched and cast in 0.009405136108398438 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 4.669431209564209\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.69403886795044 s\n",
      "SQL results fetched and cast in 0.013702869415283203 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 7.002552032470703\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.314088106155396 s\n",
      "SQL results fetched and cast in 0.009088754653930664 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 5.469488859176636\n",
      "calling pmids2vec...\n",
      "SQL join executed in 26.793946504592896 s\n",
      "SQL results fetched and cast in 0.05597329139709473 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 45.70472860336304\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.82737445831299 s\n",
      "SQL results fetched and cast in 0.008689165115356445 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 4.6605658531188965\n",
      "calling pmids2vec...\n",
      "SQL join executed in 26.500718593597412 s\n",
      "SQL results fetched and cast in 0.02335810661315918 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n",
      "elapsed: 17.530898332595825\n",
      "calling pmids2vec...\n",
      "SQL join executed in 26.417379140853882 s\n",
      "SQL results fetched and cast in 0.008654117584228516 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 10 min count\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-431a0ef04265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calling pmids2vec...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpmids2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_export_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AttentionWildfires/attention_wildfires/research_dynamics/dynamics_v2/pmids2vec.py\u001b[0m in \u001b[0;36mpmids2vec\u001b[0;34m(PMIDs, save_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params: {} dimensions, {} window size, {} min count'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"elapsed: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m             self.train(\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m             trim_rule=trim_rule, **kwargs)\n\u001b[1;32m    942\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_vocab_from_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[0;34m(self, hs, negative, wv, update, vocabulary)\u001b[0m\n\u001b[1;32m   1874\u001b[0m         \u001b[0;31m# set initial input/projection and hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv)\u001b[0m\n\u001b[1;32m   1891\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;31m# construct deterministic seed from word AND seed argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m             \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeded_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mseeded_vector\u001b[0;34m(self, seed_string, vector_size)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \u001b[0;34m\"\"\"Get a random vector (but deterministic by seed_string).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0;31m# Note: built-in hash() may vary by Python version or even (in Py3.x) per launch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0monce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/embedding-feb2020/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "for sample_id in range(N_samples):\n",
    "    model_names = []\n",
    "\n",
    "    with open(path2clusteredPMIDs, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    #print(data['pmids'])   # i_sample, i_cluster\n",
    "    sample_pmids = []\n",
    "\n",
    "    clustered_pmids = data['pmids'][str(sample_id)]\n",
    "    for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}.model'.format(\n",
    "                                sample_id, cluster_id_str, model_export_prefix)\n",
    "        model_names.append(model_export_path)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec(pmids_list, model_export_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "for sample_id in range(N_samples):\n",
    "    model_names = []\n",
    "\n",
    "    with open(path2clusteredPMIDs, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    sample_pmids = []\n",
    "\n",
    "    clustered_pmids = data['pmids'][str(sample_id)]\n",
    "    for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "        corpus_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}_corpus.json'.format(\n",
    "                                sample_id, cluster_id_str, model_export_prefix)\n",
    "        model_names.append(corpus_export_path)\n",
    "\n",
    "        print('calling pmids2corpus...')\n",
    "        pmids2corpus(pmids_list, corpus_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 25.279120922088623 s\n",
      "SQL results fetched and cast in 0.015100955963134766 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster0_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 1.5749151706695557\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.917301416397095 s\n",
      "SQL results fetched and cast in 0.0360107421875 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster1_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 3.556415557861328\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.430424690246582 s\n",
      "SQL results fetched and cast in 0.0040934085845947266 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster2_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5511379241943359\n",
      "calling pmids2vec...\n",
      "SQL join executed in 26.123147010803223 s\n",
      "SQL results fetched and cast in 0.009232044219970703 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster3_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.7747118473052979\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.3691668510437 s\n",
      "SQL results fetched and cast in 0.00411677360534668 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster4_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5644655227661133\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.905673503875732 s\n",
      "SQL results fetched and cast in 0.04102969169616699 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster0_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 3.888066530227661\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.215020179748535 s\n",
      "SQL results fetched and cast in 0.00826883316040039 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster1_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.6140182018280029\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.04189443588257 s\n",
      "SQL results fetched and cast in 0.014682531356811523 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster2_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 1.484419584274292\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.65342116355896 s\n",
      "SQL results fetched and cast in 0.0036640167236328125 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster3_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5509915351867676\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.363768577575684 s\n",
      "SQL results fetched and cast in 0.007929563522338867 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster4_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.7732067108154297\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.16311025619507 s\n",
      "SQL results fetched and cast in 0.007589101791381836 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster0_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5244522094726562\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.070780277252197 s\n",
      "SQL results fetched and cast in 0.015780210494995117 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster1_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 1.5000104904174805\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.12269163131714 s\n",
      "SQL results fetched and cast in 0.006610870361328125 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster2_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5162677764892578\n",
      "calling pmids2vec...\n",
      "SQL join executed in 24.845921277999878 s\n",
      "SQL results fetched and cast in 0.006571769714355469 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster3_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.7446722984313965\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.012343168258667 s\n",
      "SQL results fetched and cast in 0.03181600570678711 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster4_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 2.85066819190979\n",
      "calling pmids2vec...\n",
      "SQL join executed in 25.45706081390381 s\n",
      "SQL results fetched and cast in 0.0073015689849853516 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster5_2018_250k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 10 dimensions, 25 window size, 10 min count\n",
      "elapsed: 0.5897719860076904\n"
     ]
    }
   ],
   "source": [
    "# titles only (saves the corpus while training the titles-only models)\n",
    "\n",
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "for sample_id in range(N_samples):\n",
    "    model_names = []\n",
    "\n",
    "                             #  todo need much larger set of pmids since this is titles only\n",
    "    with open(path2clusteredPMIDs, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    #print(data['pmids'])   # i_sample, i_cluster\n",
    "    sample_pmids = []\n",
    "    clustered_pmids = data['pmids'][str(sample_id)]\n",
    "    for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/titles_{}_cluster{}_{}'.format(\n",
    "                sample_id, cluster_id_str, model_export_prefix)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec_titlesOnly(pmids_list, model_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
