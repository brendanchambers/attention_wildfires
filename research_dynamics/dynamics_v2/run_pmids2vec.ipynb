{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2clusteredPMIDs = 'data_processing_feb2020/pmids_1990_100k.json'\n",
    "model_export_prefix = '1990_100k'\n",
    "embed_titles_text = True\n",
    "embed_abstracts_text = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2clusteredPMIDs, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "N_samples = len(data['pmids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed abstract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}.model'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(model_export_path)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec(pmids_list, model_export_path)\n",
    "            \n",
    "    print('--------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        sample_pmids = []\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            corpus_export_path = 'data_processing_feb2020/abstracts_{}_cluster{}_{}_corpus.json'.format(\n",
    "                                    sample_id, cluster_id_str, model_export_prefix)\n",
    "            model_names.append(corpus_export_path)\n",
    "\n",
    "            print('calling pmids2corpus...')\n",
    "            pmids2corpus(pmids_list, corpus_export_path)\n",
    "            \n",
    "    print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embed titles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 338.06929993629456 s\n",
      "SQL results fetched and cast in 0.07472109794616699 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster0_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 20 min count\n",
      "elapsed: 5.802192687988281\n",
      "calling pmids2vec...\n",
      "SQL join executed in 257.70791363716125 s\n",
      "SQL results fetched and cast in 0.023283958435058594 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster1_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 6 min count\n",
      "elapsed: 2.9555301666259766\n",
      "calling pmids2vec...\n",
      "SQL join executed in 144.2593376636505 s\n",
      "SQL results fetched and cast in 0.04142260551452637 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_cluster2_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 8 min count\n",
      "elapsed: 2.1064319610595703\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 164.76679491996765 s\n",
      "SQL results fetched and cast in 0.07516837120056152 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster0_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 16 min count\n",
      "elapsed: 4.1983091831207275\n",
      "calling pmids2vec...\n",
      "SQL join executed in 144.11669278144836 s\n",
      "SQL results fetched and cast in 0.03048110008239746 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster1_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 5 min count\n",
      "elapsed: 1.4514656066894531\n",
      "calling pmids2vec...\n",
      "SQL join executed in 88.44030427932739 s\n",
      "SQL results fetched and cast in 0.010181903839111328 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_cluster2_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 6 min count\n",
      "elapsed: 1.77604079246521\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 106.3284592628479 s\n",
      "SQL results fetched and cast in 0.02272653579711914 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster0_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 19 min count\n",
      "elapsed: 2.8369343280792236\n",
      "calling pmids2vec...\n",
      "SQL join executed in 89.7604730129242 s\n",
      "SQL results fetched and cast in 0.0061495304107666016 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster1_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 6 min count\n",
      "elapsed: 0.6713864803314209\n",
      "calling pmids2vec...\n",
      "SQL join executed in 53.52023124694824 s\n",
      "SQL results fetched and cast in 0.008507013320922852 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_cluster2_1990_100k_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 7 min count\n",
      "elapsed: 0.6868195533752441\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# titles only (saves the corpus while training the titles-only models)\n",
    "\n",
    "# todo force samples to have the same size, test impact of vocabulary ? \n",
    "#    or maybe just test variance over multiple samplesets to check for effects of sample size asymmetry\n",
    "\n",
    "# load pmids\n",
    "\n",
    "if embed_titles_text:\n",
    "    \n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "                                 #  todo need much larger set of pmids since this is titles only\n",
    "        with open(path2clusteredPMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #print(data['pmids'])   # i_sample, i_cluster\n",
    "        sample_pmids = []\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "        for cluster_id_str, pmids_list in clustered_pmids.items():\n",
    "\n",
    "            model_export_path = 'data_processing_feb2020/titles_{}_cluster{}_{}'.format(\n",
    "                    sample_id, cluster_id_str, model_export_prefix)\n",
    "\n",
    "            print('calling pmids2vec...')\n",
    "            pmids2vec_titlesOnly(pmids_list, model_export_path)\n",
    "            \n",
    "        print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
