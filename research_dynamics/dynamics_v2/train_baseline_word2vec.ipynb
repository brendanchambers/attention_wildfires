{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import time\n",
    "import hdbscan\n",
    "\n",
    "\n",
    "import random\n",
    "import re\n",
    "from pmids2vec import pmids2vec, pmids2vec_titlesOnly\n",
    "from pmids2corpus import pmids2corpus    #  todo integrate this into pmids2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'data_processing_feb2020/pmids_2018_100k_baseline.json'  # name to assign exported results\n",
    "model_export_prefix = '2018_100k_baseline'\n",
    "\n",
    "K_sample = 100000   # rule of thumb - at least 5K samples per cluster for abstracts analysis\n",
    "                   #                 - at least 25K samples per cluster for titles analysis\n",
    "\n",
    "N_samplesets = 3\n",
    "year = 2018\n",
    "path2dir = '/home/brendan/FastData/pubmed2019/pubmed_data_processing/year_pmids/'  # knowledge-garden\n",
    "        #path2dir = '/project2/jevans/brendan/pubmed_data_processing/year_pmids/'  # RCC Midway2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/brendan/Projects/AttentionWildfires/attention_wildfires/mysql_config.json'\n",
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "                        # todo should move this db_name into config file\n",
    "with open(config_path, 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "    \n",
    "client_config = {'database': db_name,\n",
    "                'user': config_data['user'],\n",
    "                 'password': config_data['lock']}\n",
    "\n",
    "## init db connection\n",
    "db = pymysql.connect(**client_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N pubs: 1205220\n"
     ]
    }
   ],
   "source": [
    "filename = 'pubmed_state_{}'.format(year)\n",
    "path2pmids = path2dir + filename\n",
    "with open(path2pmids,'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "year_pub_pmids = data['publications']\n",
    "N_pubs = len(year_pub_pmids)\n",
    "print(\"N pubs: {}\".format(N_pubs))\n",
    "del data # clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "for i in range(N_samplesets):\n",
    "    samples[i] = {}\n",
    "    samples[i]['pmids'] = np.random.choice(year_pub_pmids, K_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "sample 1\n",
      "sample 2\n"
     ]
    }
   ],
   "source": [
    "pmids = {}  # for export\n",
    "for i_sample in range(N_samplesets):\n",
    "    print(\"sample {}\".format(i_sample))\n",
    "    \n",
    "    pmids[i_sample] = samples[i_sample]['pmids'].tolist()   # for export\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj = {'pmids': pmids}\n",
    "\n",
    "with open(target_file,'w') as f:\n",
    "    json.dump(save_obj, f, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2baselinePMIDs = target_file  # use the file we just saved\n",
    "embed_titles_text = True\n",
    "embed_abstracts_text = True\n",
    "\n",
    "N_samples = len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 196.97643184661865 s\n",
      "SQL results fetched and cast in 0.31641697883605957 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 1000 min count\n",
      "elapsed: 244.48808193206787\n",
      "calling pmids2vec...\n",
      "SQL join executed in 73.3527159690857 s\n",
      "SQL results fetched and cast in 0.14531159400939941 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 1000 min count\n",
      "elapsed: 96.7250874042511\n",
      "calling pmids2vec...\n",
      "SQL join executed in 62.460073709487915 s\n",
      "SQL results fetched and cast in 0.1459674835205078 s\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 1000 min count\n",
      "elapsed: 82.89348268508911\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        clustered_pmids = data['pmids'][str(sample_id)]\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/abstracts_{}_baseline_{}.model'.format(\n",
    "                                sample_id, model_export_prefix)\n",
    "        model_names.append(model_export_path)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec(pmids[sample_id], model_export_path)\n",
    "            \n",
    "    print('--------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2corpus...\n",
      "SQL join executed in 64.53848457336426 s\n",
      "SQL results fetched and cast in 0.1495356559753418 s\n",
      "saving new work to data_processing_feb2020/abstracts_0_baseline_2018_100k_baseline_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 80.74175596237183 s\n",
      "SQL results fetched and cast in 0.24747633934020996 s\n",
      "saving new work to data_processing_feb2020/abstracts_1_baseline_2018_100k_baseline_corpus.json\n",
      "calling pmids2corpus...\n",
      "SQL join executed in 73.21990871429443 s\n",
      "SQL results fetched and cast in 0.19098258018493652 s\n",
      "saving new work to data_processing_feb2020/abstracts_2_baseline_2018_100k_baseline_corpus.json\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# recreate & save the corpus for good measure\n",
    "\n",
    "if embed_abstracts_text:\n",
    "\n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        corpus_export_path = 'data_processing_feb2020/abstracts_{}_baseline_{}_corpus.json'.format(\n",
    "                                sample_id, model_export_prefix)\n",
    "        model_names.append(corpus_export_path)\n",
    "\n",
    "        print('calling pmids2corpus...')\n",
    "        pmids2corpus(pmids[sample_id], corpus_export_path)\n",
    "            \n",
    "    print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling pmids2vec...\n",
      "SQL join executed in 68.65786933898926 s\n",
      "SQL results fetched and cast in 0.4986419677734375 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_0_baseline_2018_100k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 100 min count\n",
      "elapsed: 28.23891043663025\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 71.01619362831116 s\n",
      "SQL results fetched and cast in 0.1754603385925293 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_1_baseline_2018_100k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 100 min count\n",
      "elapsed: 9.692751169204712\n",
      "---------------------------------\n",
      "calling pmids2vec...\n",
      "SQL join executed in 58.423274517059326 s\n",
      "SQL results fetched and cast in 0.10451245307922363 s\n",
      "saving corpus of titles to data_processing_feb2020/titles_2_baseline_2018_100k_baseline_titles__corpus.json\n",
      "training word2vec model...\n",
      "params: 20 dimensions, 5 window size, 100 min count\n",
      "elapsed: 4.004570960998535\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load pmids\n",
    "\n",
    "if embed_titles_text:\n",
    "    \n",
    "    for sample_id in range(N_samples):\n",
    "        model_names = []\n",
    "\n",
    "                                 #  need a large set of pmids since this is titles only\n",
    "        with open(path2baselinePMIDs, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        model_export_path = 'data_processing_feb2020/titles_{}_baseline_{}'.format(\n",
    "                sample_id, model_export_prefix)\n",
    "\n",
    "        print('calling pmids2vec...')\n",
    "        pmids2vec_titlesOnly(pmids[sample_id], model_export_path)\n",
    "            \n",
    "        print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
