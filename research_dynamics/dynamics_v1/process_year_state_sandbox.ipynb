{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  step through years and visualize in PCA space\n",
    "\n",
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mysql client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "client_config = {'unix_socket':'/home/brendanchambers/.sql.sock',\n",
    "                'database': db_name}\n",
    "output_path = '/project2/jevans/brendan/pubmed_data_processing/year_pmids/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pre-fit pca model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pca_path = '/project2/jevans/brendan/pubmed_data_processing/dimensionality_reduction_models/pca_models/pca_model0.pkl'  # more located at /project2...\n",
    "with open(pca_path, 'rb') as file:\n",
    "    pca_model = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## control params\n",
    "\n",
    "temp_altstart = 2010 # todo delete temp_altstart\n",
    "start_year = 1958\n",
    "end_year = 2018\n",
    "D_truncate = 768\n",
    "path2dir = '/project2/jevans/brendan/pubmed_data_processing/year_pmids/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load year publication pmids  & join to embeddings \n",
    "\n",
    "(todo join to text as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003...\n",
      "N pubs: 583939\n",
      "SQL join executed in 1.2565925121307373 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "SQL results fetched and cast in 537.6811707019806 s\n",
      "pca transform finished in 4.76837158203125e-07 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_pubs = False\n",
    "if process_pubs:\n",
    "    year_pubs = {}\n",
    "    for year in range(temp_altstart, end_year+1):  # todo: use start_year, delete temp_altstart\n",
    "\n",
    "        print('{}...'.format(year))\n",
    "\n",
    "        db = pymysql.connect(**client_config)\n",
    "\n",
    "        filename = 'pubmed_state_{}'.format(year)\n",
    "        path2pmids = path2dir + filename\n",
    "        with open(path2pmids,'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        year_pub_pmids = data['publications']\n",
    "        N_pubs = len(year_pub_pmids)\n",
    "        print(\"N pubs: {}\".format(N_pubs))\n",
    "        del data # clean up\n",
    "\n",
    "        str_fmt = ', '.join([str(pmid) for pmid in year_pub_pmids])\n",
    "\n",
    "        sql = '''SELECT E.pmid, E.embedding\n",
    "                FROM scibert_mean_embedding as E\n",
    "                WHERE E.pmid IN ({})'''.format(str_fmt)\n",
    "\n",
    "        start_time = time.time()\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(sql)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"SQL join executed in {} s\".format(elapsed))\n",
    "\n",
    "        start_time = time.time()\n",
    "        pub_embeddings = []\n",
    "        pub_pmids = []\n",
    "        for i,row in enumerate(cursor):\n",
    "            print_block_len = 100000\n",
    "            if i % print_block_len == 0:\n",
    "                print('fetched {} rows...'.format(print_block_len))\n",
    "            pub_pmids.append(row[0])\n",
    "            pub_embeddings.append(np.frombuffer(row[1],dtype='float16').tolist())\n",
    "        cursor.close()\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"SQL results fetched and cast in {} s\".format(elapsed))\n",
    "\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        #year_pubs[year] = pca_model.transform(pub_embeddings)[:,:D_truncate]\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"pca transform finished in {} s\".format(elapsed))\n",
    "        '''\n",
    "\n",
    "        start_time = time.time()\n",
    "        path = output_path + 'publication_embeddings/' + str(year) + '.json'\n",
    "        save_obj = {'pmids': pub_pmids,\n",
    "                    'embeddings': pub_embeddings}\n",
    "        with open(path,'w') as f:\n",
    "            json.dump(save_obj, f)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print('finished writing output file in {} s...'.format(elapsed))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load year citation pmids, join to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year_cites = {}\n",
    "\n",
    "for year in range(temp_altstart, end_year+1):  # todo change back to start_year\n",
    "    \n",
    "    print('{}...'.format(year))\n",
    "    \n",
    "    db = pymysql.connect(**client_config)\n",
    "\n",
    "    filename = 'pubmed_state_{}'.format(year)\n",
    "    path2pmids = path2dir + filename\n",
    "    with open(path2pmids,'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    year_cite_pmids = data['citations']\n",
    "    del data # clean up\n",
    "    N_citations = len(year_cite_pmids)\n",
    "    print(\"N citations: {}\".format(N_citations))\n",
    "    \n",
    "    str_fmt = ', '.join([str(pmid) for pmid in year_cite_pmids])\n",
    "    \n",
    "    sql = '''SELECT E.pmid, E.embedding\n",
    "            FROM scibert_mean_embedding as E\n",
    "            WHERE E.pmid IN ({})'''.format(str_fmt)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(\"SQL join executed in {} s\".format(elapsed))\n",
    "\n",
    "    start_time = time.time()\n",
    "    cite_embeddings = []\n",
    "    cite_pmids = []\n",
    "    for i,row in enumerate(cursor):\n",
    "        print_block_len = 100000\n",
    "        if i % print_block_len == 0:\n",
    "            print('fetched {} rows...'.format(print_block_len))\n",
    "        cite_pmids.append(row[0])\n",
    "        cite_embeddings.append(np.frombuffer(row[1],dtype='float16').tolist())\n",
    "\n",
    "    cursor.close()\n",
    "    print('fetched')\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(\"SQL results fetched and cast in {} s\".format(elapsed))\n",
    "\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    #year_cites[year] = pca_model.transform(cite_embeddings)[:,:D_truncate]\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(\"pca transform finished in {} s\".format(elapsed))\n",
    "    ''' \n",
    "        \n",
    "    start_time = time.time()\n",
    "    path = output_path + 'citation_embeddings/' + str(year) + '.json'\n",
    "    save_obj = {'pmids': cite_pmids,\n",
    "                'embeddings': cite_embeddings}\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(save_obj, f)\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print('finished writing output file in {} s'.format(elapsed))\n",
    "    \n",
    "    db.close()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check memory size for citations... don't quite understand why this is so big\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010...\n",
      "N citations: 17881767\n",
      "formatting pmids...\n",
      "finished formatting pmids.\n",
      "SQL select executed in 2263.4498505592346 s\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched 100000 rows...\n",
      "fetched\n",
      "SQL results fetched and cast in 293.8370943069458 s\n"
     ]
    }
   ],
   "source": [
    "# test using limit\n",
    "\n",
    "year = 2010\n",
    "\n",
    "print('{}...'.format(year))\n",
    "    \n",
    "db = pymysql.connect(**client_config)\n",
    "\n",
    "filename = 'pubmed_state_{}'.format(year)\n",
    "path2pmids = path2dir + filename\n",
    "with open(path2pmids,'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "year_cite_pmids = data['citations']\n",
    "del data # clean up\n",
    "N_citations = len(year_cite_pmids)\n",
    "print(\"N citations: {}\".format(N_citations))\n",
    "\n",
    "print('formatting pmids...')\n",
    "str_fmt = ', '.join([str(pmid) for pmid in year_cite_pmids])\n",
    "print('finished formatting pmids.')\n",
    "\n",
    "sql = '''SELECT E.pmid, E.embedding\n",
    "        FROM scibert_mean_embedding as E\n",
    "        WHERE E.pmid IN ({})'''.format(str_fmt)\n",
    "\n",
    "start_time = time.time()\n",
    "cursor = db.cursor()\n",
    "cursor.execute(sql)\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "print(\"SQL select executed in {} s\".format(elapsed))\n",
    "\n",
    "start_time = time.time()\n",
    "cite_embeddings = []\n",
    "cite_pmids = []\n",
    "for i,row in enumerate(cursor):\n",
    "    print_block_len = 100000\n",
    "    if i % print_block_len == 0:\n",
    "        print('fetched {} rows...'.format(print_block_len))\n",
    "    cite_pmids.append(row[0])\n",
    "    cite_embeddings.append(np.frombuffer(row[1],dtype='float16').tolist())\n",
    "\n",
    "cursor.close()\n",
    "print('fetched')\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "print(\"SQL results fetched and cast in {} s\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-588f20d1b278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m             'embeddings': cite_embeddings}\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mseparator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_item_separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path = output_path + 'citation_embeddings/' + str(year) + '.json'\n",
    "save_obj = {'pmids': cite_pmids,\n",
    "            'embeddings': cite_embeddings}\n",
    "with open(path,'w') as f:\n",
    "    json.dump(save_obj, f)\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('finished writing output file in {} s'.format(elapsed))\n",
    "\n",
    "db.close()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40215168\n",
      "40215168\n",
      "<class 'list'>\n",
      "28\n",
      "<class 'float'>\n",
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# todo partition citation sets across output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
