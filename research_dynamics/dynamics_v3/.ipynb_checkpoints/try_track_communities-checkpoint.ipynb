{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import time\n",
    "import hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'data_processing/try_track_communities.json'\n",
    "\n",
    "START_YEAR = 2003  # ~500k total abstracts in dataset\n",
    "END_YEAR = 2018    #   ~1m total abstracts in dataset\n",
    "N_years = END_YEAR - START_YEAR + 1\n",
    "\n",
    "sample_fraction = 0.02 # 0.2  # fraction of total pmids to sample\n",
    "\n",
    "# pmids for each year (for convenience)\n",
    "path2dir = '/home/brendan/FastData/pubmed2019/pubmed_data_processing/year_pmids/'  # knowledge-garden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up mysql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/home/brendan/Projects/AttentionWildfires/attention_wildfires/mysql_config.json'\n",
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "                        # todo should move this db_name into config file\n",
    "with open(config_path, 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "    \n",
    "client_config = {'database': db_name,\n",
    "                'user': config_data['user'],\n",
    "                 'password': config_data['lock']}\n",
    "\n",
    "## init db connection\n",
    "db = pymysql.connect(**client_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-fit umap model\n",
    "#   todo do this in higher dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop open pickle jar: umap model...\n"
     ]
    }
   ],
   "source": [
    "print('pop open pickle jar: umap model...')\n",
    "umap_path = \"/home/brendan/FastData/pubmed2019/pubmed_data_processing/dimensionality_reduction_models/umap2D/umap_model0.pkl\"\n",
    "with open(umap_path, 'rb') as file:\n",
    "    umap_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PMIDs(year):\n",
    "    '''\n",
    "    sample pmids from this year\n",
    "        note: relies on parameters specified above\n",
    "    '''\n",
    "    filename = 'pubmed_state_{}'.format(year)\n",
    "    path2pmids = path2dir + filename\n",
    "    with open(path2pmids,'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    year_pub_pmids = data['publications']\n",
    "    N_pubs = len(year_pub_pmids)\n",
    "    print(\"N pubs: {}\".format(N_pubs))\n",
    "    del data\n",
    "    \n",
    "    K_sample = int(N_pubs * sample_fraction)\n",
    "    print(\"K samples: {}\".format(K_sample))\n",
    "    sample_pmids = np.random.choice(year_pub_pmids, K_sample)\n",
    "    return sample_pmids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_vectors(sample_pmids):\n",
    "    '''\n",
    "    get embedding coordinates from database based on PMID list\n",
    "    '''\n",
    "    print('fetching embedding vectors from database...')\n",
    "    start_time = time.time()\n",
    "        \n",
    "    str_fmt = ', '.join([str(pmid) for pmid in sample_pmids])\n",
    "    sql = '''SELECT E.pmid, E.embedding\n",
    "            FROM scibert_mean_embedding as E\n",
    "            WHERE E.pmid IN ({})'''.format(str_fmt)\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    pub_embeddings = []\n",
    "    pub_pmids = []\n",
    "    for i,row in enumerate(cursor):\n",
    "        pub_pmids.append(row[0])\n",
    "        pub_embeddings.append(np.frombuffer(row[1],dtype='float16').tolist())\n",
    "    cursor.close()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(\"SQL query composed and executed in {} s\".format(elapsed))\n",
    "    \n",
    "    return pub_pmids, pub_embeddings\n",
    "\n",
    "def get_compressed_embedding_vectors(sample_pmids):\n",
    "    '''\n",
    "    calls get_embedding vectors\n",
    "    then runs dimensionality reduction\n",
    "    '''\n",
    "    \n",
    "    # return the pmids which have corresponding embeddings\n",
    "    pmids, embeddings = get_embedding_vectors(sample_pmids)    \n",
    "    print('compressing embedding vectors...')\n",
    "    \n",
    "    return pmids, umap_model.transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(xx, yy, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    cluster_cmap = plt.cm.viridis(np.linspace(0,1,len(unique_labels)+1))\n",
    "    \n",
    "    (f, axs) = plt.subplots(len(unique_labels),\n",
    "                           1,\n",
    "                           sharex='all',\n",
    "                           sharey='all',\n",
    "                           figsize=(4, 4*len(unique_labels)))\n",
    "        \n",
    "    for i_label, label in enumerate(unique_labels):\n",
    "                \n",
    "        xx_ = [x for (i,x) in enumerate(xx) if labels[i]==label]\n",
    "        yy_ = [y for (i,y) in enumerate(yy) if labels[i]==label]\n",
    "        \n",
    "        sns.kdeplot(xx_,\n",
    "                        yy_,\n",
    "                        shade=True,\n",
    "                        shade_lowest=False,\n",
    "                        color=cluster_cmap[i_label],\n",
    "                        ax=axs[i_label])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pmids, sample, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N pubs: 583939\n",
      "K samples: 11678\n",
      "fetching embedding vectors from database...\n",
      "SQL query composed and executed in 1.3236620426177979 s\n",
      "compressing embedding vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brendan/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../brendanchambers/.conda/envs/embedding-base/lib/python3.7/site-packages/umap/nndescent.py\", line 123:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/brendan/anaconda3/envs/embedding-feb2020/lib/python3.7/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../../../../brendanchambers/.conda/envs/embedding-base/lib/python3.7/site-packages/umap/nndescent.py\", line 134:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N abstracts fetched: 8931\n",
      "scale: 89  | min_samples: 89 \n",
      "num clusters: 12\n",
      "(13,)\n",
      "0 -1\n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "N pubs: 619853\n",
      "K samples: 12397\n",
      "fetching embedding vectors from database...\n",
      "SQL query composed and executed in 0.9254982471466064 s\n",
      "compressing embedding vectors...\n",
      "N abstracts fetched: 9649\n",
      "scale: 96  | min_samples: 96 \n",
      "num clusters: 15\n",
      "(16,)\n",
      "0 -1\n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "13 12\n",
      "14 13\n",
      "15 14\n",
      "N pubs: 656109\n",
      "K samples: 13122\n",
      "fetching embedding vectors from database...\n",
      "SQL query composed and executed in 1.9413821697235107 s\n",
      "compressing embedding vectors...\n",
      "N abstracts fetched: 10412\n",
      "scale: 104  | min_samples: 104 \n",
      "num clusters: 13\n",
      "(14,)\n",
      "0 -1\n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "13 12\n",
      "N pubs: 684653\n",
      "K samples: 13693\n",
      "fetching embedding vectors from database...\n",
      "SQL query composed and executed in 1.0668065547943115 s\n",
      "compressing embedding vectors...\n",
      "N abstracts fetched: 10593\n",
      "scale: 105  | min_samples: 105 \n",
      "num clusters: 12\n",
      "(13,)\n",
      "0 -1\n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "N pubs: 710132\n",
      "K samples: 14202\n",
      "fetching embedding vectors from database...\n",
      "SQL query composed and executed in 1.17437744140625 s\n",
      "compressing embedding vectors...\n",
      "N abstracts fetched: 11151\n",
      "scale: 111  | min_samples: 111 \n",
      "num clusters: 10\n",
      "(11,)\n",
      "0 -1\n",
      "1 0\n",
      "2 1\n",
      "3 2\n",
      "4 3\n",
      "5 4\n",
      "6 5\n",
      "7 6\n",
      "8 7\n",
      "9 8\n",
      "10 9\n",
      "N pubs: 750874\n",
      "K samples: 15017\n",
      "fetching embedding vectors from database...\n"
     ]
    }
   ],
   "source": [
    "year_data = {}\n",
    "year_data['dimensionality_reduction'] = umap_path  # version of dimensionality reduction used\n",
    "\n",
    "'''\n",
    "year_data\n",
    "    dim_reduction - e.g. umap version\n",
    "    year\n",
    "        sample_pmids\n",
    "\n",
    "'''\n",
    "\n",
    "clusterers = {}\n",
    "for i_year, year in enumerate(range(START_YEAR, END_YEAR+1)):\n",
    "\n",
    "    year_data[year] = {} # init data structure\n",
    "    \n",
    "    # get sample PMIDs published this year\n",
    "    sample_pmids = load_PMIDs(year)  # some of these don't have abstracts\n",
    "    (pmids, embeddings) = get_compressed_embedding_vectors(sample_pmids)\n",
    "    print(\"N abstracts fetched: {}\".format(len(pmids)))\n",
    "    year_data[year]['sample_pmids'] = pmids\n",
    "    year_data[year]['embedding'] = embeddings\n",
    "\n",
    "    \n",
    "    # cluster the compressed embeddings\n",
    "    clustering_scale = int(len(pmids) * 0.01) # 0.001\n",
    "    min_samples_param = int(np.min([1000, clustering_scale]))\n",
    "    print(\"scale: {}  | min_samples: {} \".format(clustering_scale, min_samples_param))\n",
    "    ####################\n",
    "    clusterers[i_year] = hdbscan.HDBSCAN(min_cluster_size=clustering_scale, # 500 for 25K # 1000 for 50K # 50 fro 2000\n",
    "                            min_samples=min_samples_param,   # 500, 1000, 50\n",
    "                            cluster_selection_method='leaf') # eom')  # euclidean distance\n",
    "    clusterers[i_year].fit(year_data[year]['embedding'])  # samples x features\n",
    "\n",
    "    # number of clusters\n",
    "    print('num clusters: {}'.format(clusterers[i_year].labels_.max()+1))\n",
    "    \n",
    "    # plot clusters\n",
    "    xx = year_data[year]['embedding'][:,0]\n",
    "    yy = year_data[year]['embedding'][:,1]\n",
    "    \n",
    "    plot_clustering(xx,yy,clusterers[i_year].labels_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(xx,yy,clusterers[i_year].labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the samples from each year\n",
    "\n",
    "(f, axs) = plt.subplots(1,\n",
    "                           N_years,\n",
    "                           sharex='all', sharey='all',\n",
    "                           figsize=(N_years,1))\n",
    "\n",
    "for i_year, year in enumerate(range(START_YEAR, END_YEAR+1)):\n",
    "    \n",
    "    xx = year_data[year]['embedding'][:,0]\n",
    "    yy = year_data[year]['embedding'][:,1]\n",
    "    \n",
    "    sns.kdeplot(xx,\n",
    "                        yy,\n",
    "                        shade=True,\n",
    "                        shade_lowest=False,\n",
    "                        cmap='Blues',\n",
    "                       ax=axs[i_year])\n",
    "    plt.title('pubs: year {}'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
