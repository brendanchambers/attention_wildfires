{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "# trying this again after adding index for year\n",
    "\n",
    "# play with some sql selections to make sure things are working\n",
    "\n",
    "# todo clean up these imports\n",
    "\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "import time\n",
    "import mysql.connector as mysql\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import Row, StructType, StructField, IntegerType, StringType\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "#import mysql.connector as mysql   # import gc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "#import igraph\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import cairocffi as cairo\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import statsmodels.api as sm  # for kdemultivariate \n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMIT_ARGS = \"--driver-class-path file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar --jars file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar pyspark-shell\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS\n",
    "\n",
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "url = \"jdbc:mysql://localhost:3306/{}?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=America/Chicago\".format(db_name)  # mysql runs on port 3306\n",
    "client_config = {'unix_socket':'/home/brendanchambers/.sql.sock',\n",
    "                'database': db_name}  # for python connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing spark\n",
      "[('spark.repl.local.jars', 'file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.jars', '/home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.driver.host', 'midway2-0058.rcc.local'), ('spark.executor.id', 'driver'), ('spark.app.name', 'pyspark-shell'), ('spark.app.id', 'local-1565063711164'), ('spark.driver.port', '45801'), ('spark.rdd.compress', 'True'), ('spark.driver.extraClassPath', 'file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.driver.memory', '28G'), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    }
   ],
   "source": [
    "print('initializing spark')\n",
    "# init spark\n",
    "conf = SparkConf()\n",
    "conf = (conf.setMaster('local[*]')\n",
    "       .set('spark.driver.memory','28G')\n",
    "       .set(\"spark.jars\", \"/home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar\"))        \n",
    "'''\n",
    ".set('spark.executor.memory','1G')  # 20\n",
    ".set('spark.driver.memory','1G')   # 40\n",
    ".set('spark.driver.maxResultSize','500M')  #.set('spark.storage.memoryFraction',0))  # this setting is now a legacy option\n",
    ".set('spark.python.worker.reuse', 'false')\n",
    ".set('spark.python.worker.memory','512m')\n",
    ".set('spark.executor.cores','1'))\n",
    "'''\n",
    "sc = SparkContext(conf=conf)\n",
    "#sc.addJar('home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar')  # temp\n",
    "spark = SparkSession(sc)  # don't need this for vanilla RDDs\n",
    "\n",
    "print(sc._conf.getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SELECT * FROM metadata) AS t\n",
      "dataframe loaded in 3.0904016494750977 s\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# test read\n",
    "\n",
    "tablename_ = 'metadata'\n",
    "\n",
    "sql = \"(SELECT * FROM {}) AS t\".format(tablename_)\n",
    "print(sql)\n",
    "\n",
    "start_time = time.time()\n",
    "df_meta = spark.read.format('jdbc').option(\"url\", url)\\\n",
    "                              .option(\"dbtable\", sql)\\\n",
    "                              .load().repartition(9).cache()\n",
    "end_time = time.time()\n",
    "print(\"dataframe loaded in {} s\".format(end_time - start_time))\n",
    "\n",
    "print(df_meta.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.07869338989257812\n",
      "(24275634, 'Multimodal Sensory Distortions in Postpartum Exacerbation of Schizophrenia.', 2017)\n",
      "\n",
      "(30225395, None, 2017)\n",
      "\n",
      "(30225396, 'The Challenging Conundrum of Diagnosing and Managing', 2017)\n",
      "\n",
      "(30225397, 'Practical Strategies for Assessing Patient Physical Activity Levels in Primary Care.', 2017)\n",
      "\n",
      "(30225398, 'Nonexercise Estimated Cardiorespiratory Fitness and Mortality Due to All Causes and Cardiovascular Disease: The NHANES III Study.', 2017)\n",
      "\n",
      "(30225399, 'National Trends in the Incidence, Management, and Outcomes of Heart Failure Complications in Patients Hospitalized for ST-Segment Elevation Myocardial Infarction.', 2017)\n",
      "\n",
      "(30225400, 'Acute Alcoholic Hepatitis: Natural History and Predictors of Mortality Using a Multicenter Prospective Study.', 2017)\n",
      "\n",
      "(30225401, 'Experience and Outcomes at a Specialized', 2017)\n",
      "\n",
      "(30225402, 'Normalization of Testosterone Levels After Testosterone Replacement Therapy Is Not Associated With Reduced Myocardial Infarction in Smokers.', 2017)\n",
      "\n",
      "(30225403, 'Combined Association of Cardiorespiratory Fitness and Body Fatness With Cardiometabolic Risk Factors in Older Norwegian Adults: The Generation 100 Study.', 2017)\n",
      "\n",
      "(30225404, 'Pretravel Health Preparation of International Travelers: Results From the Boston Area Travel Medicine Network.', 2017)\n",
      "\n",
      "(30225405, 'Effect of Antimicrobial Stewardship Program Guidance on the Management of Uncomplicated Skin and Soft Tissue Infections in Hospitalized Adults.', 2017)\n",
      "\n",
      "(30225406, 'Automated Diabetes Case Identification Using Electronic Health Record Data at a Tertiary Care Facility.', 2017)\n",
      "\n",
      "(30225407, 'A Rare', 2017)\n",
      "\n",
      "(30225408, \"Science of Health Care Delivery: An Innovation in Undergraduate Medical Education to Meet Society's Needs.\", 2017)\n",
      "\n",
      "(30225409, 'A Multifaceted Organizational Physician Assessment Program: Validity Evidence and Implications for the Use of Performance Data.', 2017)\n",
      "\n",
      "(30225410, 'Development of an Interdisciplinary Pediatric Pain Rehabilitation Program: The First 1000 Consecutive Patients.', 2017)\n",
      "\n",
      "elapsed time: 62.97846961021423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the same query with python mysql connector\n",
    "\n",
    "# RESULTS this is slower than the pyspark dataframe method\n",
    "#   suggesting that the indexed columns are being used smartly by pyspark\n",
    "#   while also utilizing parallelization\n",
    "\n",
    "# ~56 s for 2007\n",
    "# ~62 s for 2017\n",
    "\n",
    "\n",
    "year_ = 2017\n",
    "sql = 'SELECT pmid FROM metadata WHERE year = {};'.format(year_)\n",
    "\n",
    "db = mysql.connect(**client_config)\n",
    "cursor = db.cursor()\n",
    "start_time = time.time()\n",
    "cursor.execute(sql)\n",
    "print('elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "published_pmids = cursor.fetchall()\n",
    "\n",
    "print('elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT pmid FROM metadata WHERE year = 1959;\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o156.load.\n: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'SELECT pmid FROM metadata WHERE year = 1959; WHERE 1=0' at line 1\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:955)\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1005)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:60)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation.<init>(JDBCRelation.scala:115)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:52)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:341)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:164)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-573fd67a1ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jdbc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                               \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dbtable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                               \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/spark-2.3.2-el7-x86_64/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/spark-2.3.2-el7-x86_64/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/embedding-base/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o156.load.\n: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'SELECT pmid FROM metadata WHERE year = 1959; WHERE 1=0' at line 1\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:955)\n\tat com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1005)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:60)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation.<init>(JDBCRelation.scala:115)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:52)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:341)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:164)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "# get cited papers\n",
    "\n",
    "\n",
    "# use jdbc to execute sql join and then count using pyspark dataframe\n",
    "\n",
    "tablename_ = 'citations'\n",
    "\n",
    "year_ = 1959\n",
    "sql = 'SELECT pmid FROM metadata WHERE year = {};'.format(year_)  # filter using JOIN todo\n",
    "print(sql)\n",
    "\n",
    "start_time = time.time()\n",
    "df = spark.read.format('jdbc').option(\"url\", url)\\\n",
    "                              .option(\"dbtable\", sql)\\\n",
    "                              .load().repartition(9).cache()\n",
    "end_time = time.time()\n",
    "print(\"dataframe loaded in {} s\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT pmid FROM metadata WHERE year = 1959;\n",
      "elapsed time: 0.7483458518981934\n",
      "[24545123, 24545124, 24545125, 24545126, 24545127, 24545140, 24545141, 24545142, 24545143, 24545144]\n"
     ]
    }
   ],
   "source": [
    "# sample query (ok to delete)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 1959;\n",
      "[12997665, 13149802, 13568043, 13568047, 13588436, 13621645, 21009155, 15402898, 12999049, 14910862]\n",
      "elapsed time: 1.9896306991577148\n"
     ]
    }
   ],
   "source": [
    "# sample join\n",
    "\n",
    "# ~1 s for 1959\n",
    "# ~20 min for 2017\n",
    "\n",
    "db = mysql.connect(**client_config)\n",
    "year_ = 1959\n",
    "sql = '''SELECT referenced\n",
    "            FROM citations \n",
    "                LEFT JOIN metadata\n",
    "                ON citations.citing = metadata.pmid\n",
    "            WHERE year = {};'''.format(year_)  # filter using JOIN todo\n",
    "\n",
    "print(sql)\n",
    "cursor = db.cursor()\n",
    "start_time = time.time()\n",
    "cursor.execute(sql)\n",
    "year_citations = [x for [x] in cursor.fetchall()]\n",
    "print(year_citations[:10])\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print('elapsed time: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = {'publications': year_publications,\n",
    "            'citations': year_citations}\n",
    "\n",
    "with open('json/pubmed_state_{}'.format(year_), 'w') as f:\n",
    "    json.dump(save_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT pmid FROM metadata WHERE year = 2004;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2004;\n",
      "elapsed time: 435.9970154762268\n",
      "SELECT pmid FROM metadata WHERE year = 2005;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2005;\n",
      "elapsed time: 397.86027431488037\n",
      "SELECT pmid FROM metadata WHERE year = 2006;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2006;\n",
      "elapsed time: 443.1734552383423\n",
      "SELECT pmid FROM metadata WHERE year = 2007;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2007;\n",
      "elapsed time: 439.329074382782\n",
      "SELECT pmid FROM metadata WHERE year = 2008;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2008;\n",
      "elapsed time: 469.04860734939575\n",
      "SELECT pmid FROM metadata WHERE year = 2009;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2009;\n",
      "elapsed time: 516.3298850059509\n",
      "SELECT pmid FROM metadata WHERE year = 2010;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2010;\n",
      "elapsed time: 520.7007312774658\n",
      "SELECT pmid FROM metadata WHERE year = 2011;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2011;\n",
      "elapsed time: 655.102498292923\n",
      "SELECT pmid FROM metadata WHERE year = 2012;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2012;\n",
      "elapsed time: 699.3571071624756\n",
      "SELECT pmid FROM metadata WHERE year = 2013;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2013;\n",
      "elapsed time: 719.3731243610382\n",
      "SELECT pmid FROM metadata WHERE year = 2014;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2014;\n",
      "elapsed time: 870.3945982456207\n",
      "SELECT pmid FROM metadata WHERE year = 2015;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2015;\n",
      "elapsed time: 928.5486478805542\n",
      "SELECT pmid FROM metadata WHERE year = 2016;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2016;\n",
      "elapsed time: 972.7449789047241\n",
      "SELECT pmid FROM metadata WHERE year = 2017;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2017;\n",
      "elapsed time: 951.476663351059\n",
      "SELECT pmid FROM metadata WHERE year = 2018;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2018;\n",
      "elapsed time: 757.2447612285614\n",
      "SELECT pmid FROM metadata WHERE year = 2019;\n",
      "SELECT referenced\n",
      "            FROM citations \n",
      "                LEFT JOIN metadata\n",
      "                ON citations.citing = metadata.pmid\n",
      "            WHERE year = 2019;\n",
      "elapsed time: 357.92827796936035\n"
     ]
    }
   ],
   "source": [
    "#  loop through the years and produce published pmids and cited pmids\n",
    "#    since I'm hurrying, just grabbing the code from above and copying\n",
    "\n",
    "for year_ in range(2004, 2020): #  range(1958, 2018):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # get published article pmids from this year\n",
    "    sql = 'SELECT pmid FROM metadata WHERE year = {};'.format(year_)  # filter using JOIN todo\n",
    "    print(sql)\n",
    "    \n",
    "    db = mysql.connect(**client_config)\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    year_publications = [x for [x] in cursor.fetchall()]\n",
    "\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    \n",
    "    # get cited article pmids from this year\n",
    "    sql = '''SELECT referenced\n",
    "            FROM citations \n",
    "                LEFT JOIN metadata\n",
    "                ON citations.citing = metadata.pmid\n",
    "            WHERE year = {};'''.format(year_)  # filter using JOIN todo\n",
    "\n",
    "    print(sql)\n",
    "    db = mysql.connect(**client_config)\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    year_citations = [x for [x] in cursor.fetchall()]\n",
    "    \n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    \n",
    "    # write to json file\n",
    "    save_data = {'publications': year_publications,\n",
    "            'citations': year_citations}\n",
    "    with open('json/pubmed_state_{}'.format(year_), 'w') as f:\n",
    "        json.dump(save_data, f)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('elapsed time: {}'.format(end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
