{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the database\n",
    "\n",
    "# think about how to set up the contextual embedding training pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import Row, StructType, StructField, IntegerType, StringType\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "#import mysql.connector as mysql   # import gc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMIT_ARGS = \"--driver-class-path file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar --jars file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar pyspark-shell\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS\n",
    "\n",
    "db_name = 'test_pubmed'  # db name collisons? https://stackoverflow.com/questions/14011968/user-cant-access-a-database\n",
    "table_name = 'abstracts' # 'abstracts'\n",
    "\n",
    "url = \"jdbc:mysql://localhost:3306/{}?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=America/Chicago\".format(db_name)  # mysql runs on port 3306\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing spark\n",
      "[('spark.driver.memory', '24G'), ('spark.repl.local.jars', 'file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.app.id', 'local-1563565969652'), ('spark.jars', '/home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.driver.port', '41993'), ('spark.executor.id', 'driver'), ('spark.app.name', 'pyspark-shell'), ('spark.rdd.compress', 'True'), ('spark.driver.extraClassPath', 'file:///home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar'), ('spark.serializer.objectStreamReset', '100'), ('spark.driver.host', 'midway2-0085.rcc.local'), ('spark.master', 'local[*]'), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    }
   ],
   "source": [
    "print('initializing spark')\n",
    "# init spark\n",
    "conf = SparkConf()\n",
    "conf = (conf.setMaster('local[*]')\n",
    "       .set('spark.driver.memory','24G')\n",
    "       .set(\"spark.jars\", \"/home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar\"))        \n",
    "'''\n",
    ".set('spark.executor.memory','1G')  # 20\n",
    ".set('spark.driver.memory','1G')   # 40\n",
    ".set('spark.driver.maxResultSize','500M')  #.set('spark.storage.memoryFraction',0))  # this setting is now a legacy option\n",
    ".set('spark.python.worker.reuse', 'false')\n",
    ".set('spark.python.worker.memory','512m')\n",
    ".set('spark.executor.cores','1'))\n",
    "'''\n",
    "sc = SparkContext(conf=conf)\n",
    "#sc.addJar('home/brendanchambers/my_resources/mysql-connector-java-8.0.16/mysql-connector-java-8.0.16.jar')  # temp\n",
    "spark = SparkSession(sc)  # don't need this for vanilla RDDs\n",
    "\n",
    "print(sc._conf.getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SELECT * FROM abstracts LIMIT 100000) AS t\n",
      "dataframe loaded in 0.06559634208679199 s\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# test read\n",
    "\n",
    "sql = \"(SELECT * FROM {} LIMIT 100000) AS t\".format(table_name)\n",
    "print(sql)\n",
    "\n",
    "start_time = time.time()\n",
    "df = spark.read.format('jdbc').option(\"url\", url)\\\n",
    "                              .option(\"dbtable\", sql)\\\n",
    "                              .load().repartition(9).cache()\n",
    "end_time = time.time()\n",
    "print(\"dataframe loaded in {} s\".format(end_time - start_time))\n",
    "\n",
    "print(df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(pmid='17616371', title='Preventing the self-adherence of Mefix.', abstract='')\n",
      "\n",
      "Row(pmid='17532617', title='Closed cycle construction: an integrated process for the separation and reuse of C&D waste.', abstract=\"In The Netherlands, construction and demolition (C&D) waste is already to a large extent being reused, especially the stony fraction, which is crushed and reused as a road base material. In order to increase the percentage of reuse of the total C&D waste flow to even higher levels, a new concept has been developed. In this concept, called 'Closed Cycle Construction', the processed materials are being reused at a higher quality level and the quantity of waste that has to be disposed of is minimised. For concrete and masonry, the new concept implies that the material cycle will be completely closed, and the original constituents (clay bricks, gravel, sand, cement stone) are recovered in thermal processes. The mixed C&D waste streams are separated and decontaminated. For this purpose several dry separation techniques are being developed. The quality of the stony fraction is improved so much, that this fraction can be reused as an aggregate in concrete. The new concept has several benefits from a sustainability point of view, namely less energy consumption, less carbon dioxide emission, less waste production and less land use (for excavation and disposal sites). One of the most remarkable benefits of the new concept is that the thermal process steps are fuelled with the combustible fraction of the C&D waste itself. Economically the new process is more or less comparable with the current way of processing C&D waste. On the basis of the positive results of a feasibility study, currently a pilot and demonstration project is being carried out. The aim is to optimise the different process steps of the Closed Cycle Construction process on a laboratory scale, and then to verify them on a large scale. The results of the project are promising, so far. \")\n",
      "\n",
      "Row(pmid='8863746', title='Sequence analysis of the beta B2-crystallin cDNA of hamster containing a domain conserved among vertebrates.', abstract='The cDNA sequence of the beta B2-cry was determined from hamster (Mesocricetus auratus) and compared to the corresponding genes of bovine, frog, chicken, human, mouse and rat. Multispecies comparison demonstrated high homology between the hamster, rat and mouse gene, but larger distances to man, bovine, chicken and frog. There is striking identity within a strech of 36 deduced amino acids (aa) between the Greek key motif 3 and part of motif 4. This 36-aa domain contains a putative phosphorylation site for protein kinase C and is highly conserved among all known basic beta B-Cry; however, it can neither be detected in the acidic beta A-nor in the gamma-Cry. ')\n",
      "\n",
      "\n",
      "show operation. elapsed: 0.08284640312194824 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "test_subset = df.take(3)\n",
    "end_time = time.time()\n",
    "\n",
    "for entry in test_subset:\n",
    "    print(entry)\n",
    "    print()\n",
    "print()\n",
    "print(\"show operation. elapsed: {} s\".format(end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
